{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8NRDPfbuZzc"
      },
      "outputs": [],
      "source": [
        "!pip install langchain unstructured openai tiktoken python-magic chromadb tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "YYbWDvuNuf7O",
        "outputId": "0c8537ad-1fd8-4f84-8a3a-36ea56b3214a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<font color='blue'><b>Preparing documents...</b></font>"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      0. Quit\n",
            "      1. Summarization\n",
            "      2. Question-Answering (General)\n",
            "      3. Question-Answering (Precise)\n",
            "      4. Classification (Technical/Non-Technical)\n",
            "\n",
            "      Which action would you like to perform? (Enter between 0-4)\n",
            "\n",
            "      1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<font color='blue'><b>Summarizing...</b></font>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<font color='red'><b>!!! Something has gone wrong, try again... !!!</b></font>"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import os\n",
        "import csv\n",
        "import math\n",
        "import nltk\n",
        "import glob\n",
        "import json\n",
        "import magic\n",
        "import random\n",
        "import datetime\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from datetime import timedelta\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from IPython.display import Markdown, display\n",
        "from langchain.document_loaders import DirectoryLoader\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.prompts.chat import (\n",
        "    ChatPromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        ")\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"HERE IS THE API KEY\"\n",
        "\n",
        "def customDisplay(text, color=\"blue\"):\n",
        "  display(Markdown(f\"<font color='{color}'><b>{text}</b></font>\"))\n",
        "\n",
        "def writeResponse(response, idx):\n",
        "  with open(f\"results/result_{idx}.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(response)\n",
        "\n",
        "def prepareData():\n",
        "  customDisplay(\"Preparing documents...\")\n",
        "\n",
        "  !rm -rf \"./data\"\n",
        "  os.makedirs(\"data\")\n",
        "\n",
        "  csv_files = glob.glob(\"*.csv\")\n",
        "\n",
        "  for idx, cf in enumerate(csv_files):\n",
        "    sep = \",\"\n",
        "    skiprows = []\n",
        "\n",
        "    with open(cf, \"r\", encoding=\"utf-8\") as f:\n",
        "      line = f.readline().split(\"sep=\")\n",
        "\n",
        "      if len(line) > 1:\n",
        "        skiprows.append(0)\n",
        "        sep = line[1][:-1]\n",
        "\n",
        "    data = pd.read_csv(cf, sep=sep, skiprows=skiprows)\n",
        "\n",
        "    # prepare intermediate documents\n",
        "    with open(f\"data/file_{idx}.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
        "      for _, row in data.iterrows():\n",
        "        if str(row[\"Comment\"]) != row[\"Comment\"]:\n",
        "          continue\n",
        "\n",
        "        f.write(\n",
        "          json.dumps(\n",
        "            str({\n",
        "              \"date\": row[\"Date\"],\n",
        "              \"comment\": row[\"Comment\"]\n",
        "            })\n",
        "          ) + \"\\n\"\n",
        "        )\n",
        "\n",
        "  # load entire documents\n",
        "  loader = DirectoryLoader(\"data\", glob=f\"**/*.jsonl\")\n",
        "  documents = loader.load()\n",
        "\n",
        "  # split the documents into chunks\n",
        "  text_splitter = RecursiveCharacterTextSplitter(\n",
        "      chunk_size = 2000,\n",
        "      chunk_overlap  = 0,\n",
        "      length_function = len,\n",
        "  )\n",
        "\n",
        "  return text_splitter.split_documents(documents)\n",
        "\n",
        "''' ALL ACTIONS '''\n",
        "def summarization(texts):\n",
        "  customDisplay(\"Summarizing...\")\n",
        "\n",
        "  # initializing the Summary chain\n",
        "  chain = load_summarize_chain(llm=ChatOpenAI(), chain_type=\"refine\")\n",
        "\n",
        "  response = chain.run(texts)\n",
        "  display(Markdown(f\"Summary: <b>{response}</b>\"))\n",
        "\n",
        "def qaGeneral(texts):\n",
        "  customDisplay(\"Preparing for QA(General)...\")\n",
        "\n",
        "  # embed all those chunks and store them into a vectorDB (chroma)\n",
        "  embeddings = OpenAIEmbeddings(openai_api_key=os.environ[\"OPENAI_API_KEY\"])\n",
        "  docsearch = Chroma.from_documents(texts, embeddings)\n",
        "\n",
        "  # initialize the QA model\n",
        "  qa = RetrievalQA.from_llm(llm=ChatOpenAI(), retriever=docsearch.as_retriever(), return_source_documents=True)\n",
        "\n",
        "  customDisplay(\"Type 'exit' to quit.\\n\")\n",
        "\n",
        "  # QA loop\n",
        "  while True: \n",
        "    query = input(\"Ques: \")\n",
        "    if query == \"exit\": break\n",
        "\n",
        "    response = qa({\"query\": query})\n",
        "    display(Markdown(f\"Ans: <b>{response['result']}</b>\"))\n",
        "    # print('source_documents', response['source_documents'])\n",
        "\n",
        "def qaPrecise(texts):\n",
        "  customDisplay(\"Preparing for QA(Precise)...\")\n",
        "\n",
        "  # initialize the QA chain\n",
        "  chain = load_qa_chain(llm=ChatOpenAI(), chain_type=\"map_rerank\")\n",
        "\n",
        "  customDisplay(\"Type 'exit' to quit.\\n\")\n",
        "  \n",
        "  # QA loop\n",
        "  while True: \n",
        "    query = input(\"Ques: \")\n",
        "    if query == \"exit\": break\n",
        "\n",
        "    response = chain({\"input_documents\": texts, \"question\": query}, return_only_outputs=True)\n",
        "    display(Markdown(f\"Ans: <b>{response['output_text']}</b>\"))\n",
        "    # print('source_documents', response['source_documents'])\n",
        "\n",
        "def classification():\n",
        "  customDisplay(\"Classifying comments between Technical and Non-Technical one by one...\")\n",
        "\n",
        "  human_message_prompt = HumanMessagePromptTemplate(\n",
        "      prompt=PromptTemplate(\n",
        "          input_variables=[\"comment\"],\n",
        "          template='''\n",
        "Classify this comment into 'technical' and 'non_technical'. Ans should be either 'technical' and 'non_technical'. Don't try to describe it:\n",
        "\n",
        "Example:\n",
        "Makes it hard to find info\n",
        "technical\n",
        "\n",
        "{comment}\n",
        "          ''',\n",
        "      )\n",
        "  )\n",
        "\n",
        "  chat = ChatOpenAI(temperature=0)\n",
        "  chat_prompt_template = ChatPromptTemplate.from_messages([human_message_prompt])\n",
        "\n",
        "  # initialize the classification model\n",
        "  chain = LLMChain(llm=chat, prompt=chat_prompt_template, verbose=False)\n",
        "\n",
        "  !rm -rf \"./classifications\"\n",
        "  os.makedirs(\"classifications\")\n",
        "\n",
        "  files = glob.glob(\"*.csv\")\n",
        "\n",
        "  # classification loop\n",
        "  for file in files:\n",
        "    sep = \",\"\n",
        "    skiprows = []\n",
        "\n",
        "    with open(file, \"r\", encoding=\"utf-8\") as f:\n",
        "      line = f.readline().split(\"sep=\")\n",
        "\n",
        "      if len(line) > 1:\n",
        "        skiprows.append(0)\n",
        "        sep = line[1][:-1]\n",
        "\n",
        "    res = []\n",
        "    data = pd.read_csv(file, sep=sep, skiprows=skiprows)\n",
        "\n",
        "    with tqdm(total=len(data)) as pbar:\n",
        "      for idx, row in data.iterrows():\n",
        "        r = chain.run(row[\"Comment\"]) if str(row[\"Comment\"]) == row[\"Comment\"] else \"\"\n",
        "        res.append(r)\n",
        "        pbar.update(1)\n",
        "    \n",
        "    data[\"Classification\"] = res\n",
        "    data.to_csv(f\"classifications/{file}\", sep=\",\")\n",
        "\n",
        "  customDisplay(\"Done, Open 'classifications' folder to see the results.\")\n",
        "\n",
        "def askAI():\n",
        "  csv_files = glob.glob(\"*.csv\")\n",
        "\n",
        "  if len(csv_files) == 0:\n",
        "    customDisplay(\"!!! No CSV file found !!!\", \"red\")\n",
        "    return\n",
        "    \n",
        "  texts = prepareData()\n",
        "\n",
        "  while True:\n",
        "    # getting action type\n",
        "    at = int(input(\n",
        "      '''\n",
        "      0. Quit\n",
        "      1. Summarization\n",
        "      2. Question-Answering (General)\n",
        "      3. Question-Answering (Precise)\n",
        "      4. Classification (Technical/Non-Technical)\n",
        "\n",
        "      Which action would you like to perform? (Enter between 0-4)\n",
        "\n",
        "      '''  \n",
        "    ))\n",
        "\n",
        "    if int(at) == at and at >= 0 and at <= 4:\n",
        "      if at == 0:\n",
        "        customDisplay(\"Quitting...\")\n",
        "        break\n",
        "      else:\n",
        "        try:\n",
        "          if at == 1:\n",
        "            summarization(texts)\n",
        "          elif at == 2:\n",
        "            qaGeneral(texts)\n",
        "          elif at == 3:\n",
        "            qaPrecise(texts)\n",
        "          else:\n",
        "            classification()\n",
        "        except:\n",
        "          customDisplay(\"!!! Something has gone wrong, try again... !!!\", \"red\")\n",
        "\n",
        "'''FINALLY RUNNING THIS SCRIPT'''\n",
        "askAI()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}