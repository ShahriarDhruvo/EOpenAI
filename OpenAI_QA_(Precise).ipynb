{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W0LwUqGYnpXF"
      },
      "outputs": [],
      "source": [
        "!pip install langchain unstructured openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import nltk\n",
        "import json\n",
        "import magic\n",
        "import random\n",
        "import datetime\n",
        "import pandas as pd\n",
        "from datetime import timedelta\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from IPython.display import Markdown, display\n",
        "from langchain.document_loaders import DirectoryLoader\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "!rm -rf './data'\n",
        "os.makedirs('data')\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"HERE IS THE API KEY\"\n",
        "\n",
        "def genRandomDate():\n",
        "  end_date = datetime.datetime.now()\n",
        "  start_date = end_date - timedelta(days=1000)\n",
        "  return str(start_date + (end_date - start_date) * random.random())\n",
        "\n",
        "def genRandomUser():\n",
        "  users = [\"Poppyhead\", \"Zygomatic\", \"Calathus\", \"Skedaddle\", \"Negative\", \"Rejigger\", \"Apolaustic\", \"Phalanx\", \"Havelock\", \"Sardoodledom\", \"Galimatias\", \"Palomino\", \"Thaumatogeny\", \"Piffling\", \"Vaniloquence\", \"Trencherman\", \"Pilgarlic\", \"Curlicue\", \"KilimZol\", \"EnchanMizzen\", \"Ludicrism\", \"DartmoorYawp\", \"Anorchous\", \"Umpteen\", \"IquidDuck\", \"JcavalJunket\", \"Symptosis\", \"RuffminOxter\", \"Luciform\", \"Antimacassar\", \"Onomatopoeia\", \"Blackguard\", \"Xerotripsis\", \"Orgulous\", \"Almacantar\", \"Comeuppance\", \"ChichimWonky\", \"Logorrhea\", \"Knickknack\", \"Cornucopia\", \"Rupellary\", \"Peewee\", \"Armigerous\", \"Gardyloo\", \"Nephralgia\", \"Piccadilly\", \"Aleeman171999\", \"Harebrained\", \"Nektonseph2004\", \"Limburger\", \"Zonulet\", \"Sambur\", \"Aasvogel\", \"Primp\", \"Cinemuck\", \"Jubilee\", \"Capripede\", \"Flophouse\", \"Tachyphrasia\", \"Ephemeral\", \"Paraenesis\", \"Normalcy\", \"Morwolf1596\", \"Hotbed\", \"Limnguinhd\", \"Parapet\", \"Ateknia\", \"Taradiddle\", \"Blowback\", \"Kudzu\", \"Opsiometer\", \"Outflow\", \"Prismatic\", \"Roundabout\", \"Bellycheer\", \"Ewer\", \"Rabblefalnd\", \"Mufti\", \"Anemograph\", \"Cheeky\"]\n",
        "  return random.choice(users)\n"
      ],
      "metadata": {
        "id": "gzj0n7PEnwnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"test.csv\", delimiter=\",\")\n",
        "\n",
        "with open(f'data/file.jsonl', 'w', encoding='utf-8') as f:\n",
        "  for row in data['review']:\n",
        "    f.write(json.dumps(str({\n",
        "        'username': genRandomUser(),\n",
        "        'commented_on': genRandomDate(),\n",
        "        'comment': row.split('READ MORE')[0]\n",
        "    })) + '\\n')"
      ],
      "metadata": {
        "id": "NLrawbkrvHVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load all documents\n",
        "loader = DirectoryLoader('data', glob=\"**/*.jsonl\")\n",
        "documents = loader.load()\n",
        "\n",
        "# split the documents into chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 2000,\n",
        "    chunk_overlap  = 0,\n",
        "    length_function = len,\n",
        ")\n",
        "\n",
        "texts = text_splitter.split_documents(documents)\n",
        "\n",
        "# initialize the QA chain\n",
        "chain = load_qa_chain(llm=ChatOpenAI(), chain_type='map_rerank')"
      ],
      "metadata": {
        "id": "o2kv09aGvL91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts[:5]"
      ],
      "metadata": {
        "id": "RyfccVt6B-aO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True: \n",
        "  query = input(\"Ques: \")\n",
        "  if query == \"exit\": break\n",
        "\n",
        "  response = chain({\"input_documents\": texts[:5], \"question\": query}, return_only_outputs=True)\n",
        "  display(Markdown(f\"Ans: <b>{response['output_text']}</b>\"))\n",
        "  # print('source_documents', response['source_documents'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "id": "4aYkCGZqvQ0s",
        "outputId": "dba35eb8-50d6-44d1-95a6-bfbfd3d426d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ques: Who said \"Reason why I hvnt thrown it away yet : decent sound quality\"?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Ans: <b>Mufti</b>"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ques: exit\n"
          ]
        }
      ]
    }
  ]
}