{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "643CoflFWI2Y"
      },
      "outputs": [],
      "source": [
        "!pip install langchain openai unstructured"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "import pandas as pd\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from IPython.display import Markdown, display\n",
        "from langchain.document_loaders import DirectoryLoader\n",
        "from langchain.document_loaders.csv_loader import CSVLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.prompts.chat import (\n",
        "    ChatPromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        ")\n",
        "\n",
        "!rm -rf './data'\n",
        "!rm -f 'result.md'\n",
        "os.makedirs('data')\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"HERE IS THE API KEY\"\n",
        "\n",
        "human_message_prompt = HumanMessagePromptTemplate(\n",
        "    prompt=PromptTemplate(\n",
        "        input_variables=[\"comments\"],\n",
        "        template=\"Classify following comments into Technical and Non-technical:\\n\\n\\n{comments}\",\n",
        "    )\n",
        ")\n",
        "\n",
        "chat = ChatOpenAI(temperature=0)\n",
        "chat_prompt_template = ChatPromptTemplate.from_messages([human_message_prompt])"
      ],
      "metadata": {
        "id": "kQhbaXZdWUrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"test.csv\", delimiter=\",\")\n",
        "\n",
        "with open('data/file.txt', 'w', encoding='utf-8') as f:\n",
        "  for row in data['review']:\n",
        "    f.write(row.split('READ MORE')[0] + '\\n')"
      ],
      "metadata": {
        "id": "3svllBQ5mh81"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load all documents\n",
        "loader = DirectoryLoader('data', glob=\"**/*.txt\")\n",
        "documents = loader.load()\n",
        "\n",
        "# split the documents into chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 2000,\n",
        "    chunk_overlap  = 0,\n",
        "    length_function = len,\n",
        ")\n",
        "\n",
        "texts = text_splitter.split_documents(documents)\n",
        "\n",
        "# initialize the classification model\n",
        "chain = LLMChain(llm=chat, prompt=chat_prompt_template, verbose=False)\n",
        "\n",
        "def writeResponse(response):\n",
        "  with open('result.md', 'a', encoding='utf-8') as f:\n",
        "    f.write(response)"
      ],
      "metadata": {
        "id": "sG_JM7t6lzRD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, text in enumerate(texts):\n",
        "  if idx > 1: break\n",
        "\n",
        "  response = chain.run(text.page_content)\n",
        "  # writeResponse(response)\n",
        "  display(Markdown(f\"Ans: <b>{response}</b>\"))"
      ],
      "metadata": {
        "id": "C7GB6JbRWPrL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}